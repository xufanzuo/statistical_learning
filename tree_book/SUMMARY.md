# Summary

* [Introduction](README.md)
* [Chapter1 统计学习方法概论](Chapter1/C1.md)
* [Chapter2 感知机](Chapter2/C2.md)
    * [Section2.1 感知机学习策略](Chapter2/s2.1.md)
    * [Section2.2 感知机学习算法](Chapter2/s2.2.md)
* [Chapter3 K近邻法](Chapter3/C3.md)
    * [Section3.1 K近邻模型](Chapter3/s3.1.md)
    * [Section3.1 K近邻模型的实现](Chapter3/s3.2.md)
* [Chapter4 朴素贝叶斯](Chapter4/C4.md)
    * [Section4.1 朴素贝叶斯的学习与分类](Chapter4/s4.1.md)
    * [Section4.2 朴素贝叶斯的参数估计](Chapter4/s4.2.md)
* [Chapter5 决策树](Chapter5/C5.md)
    * [Section5.1 决策树模型与学习](Chapter5/s5.1.md)
    * [Section5.2 特征选择](Chapter5/s5.2.md)
    * [Section5.3 决策树的生成](Chapter5/s5.3.md)
    * [Section5.4 CART算法](Chapter5/s5.4.md)
* [Chapter6 逻辑斯蒂回归与最大熵模型](Chapter6/C6.md)
    * [Section6.1 逻辑斯蒂回归模型](Chapter6/s6.1.md)
    * [Section6.2 最大熵模型](Chapter6/s6.2.md)
    * [Section6.3 模型学习的最优化算法](Chapter6/s6.3.md)
* [Chapter7 支持向量机](Chapter7/C7.md)
    * [Section7.1 线性可分支持向量机与硬间隔最大化](Chapter7/s7.1.md)
    * [Section7.2 线性支持向量机与软间隔最大化](Chapter7/s7.2.md)
    * [Section7.3 非线性支持向量机与核函数](Chapter7/s7.3.md)
    * [Section7.4 序列最小最优化算法](Chapter7/s7.4.md)
* [Chapter8 提升方法](Chapter8/C8.md)
    * [Section8.1 提升方法AdaBoost算法](Chapter8/s8.1.md)
    * [Section8.2 AdaBoost算法的解释](Chapter8/s8.2.md)
    * [Section8.3 提升树](Chapter8/s8.3.md)
* [Chapter9 EM算法及其推广](Chapter9/C9.md)
    * [Section9.1 EM算法引入和收敛](Chapter9/s9.1.md)
    * [Section9.2 EM算法的推广](Chapter9/s9.2.md)
* [Chapter10 隐马尔可夫模型](Chapter10/C10.md)
    * [Section10.1 隐马尔可夫模型的基本概念](Chapter10/s10.1.md)
    * [Section10.2 概率计算方法](Chapter10/s10.2.md)
    * [Section10.3 学习算法](Chapter10/s10.3.md)
    * [Section10.4 预测算法](Chapter10/s10.4.md)
* [Chapter11 条件随机场](Chapter11/C11.md)
    * [Section11.1 概率无向图模型](Chapter11/s11.1.md)
    * [Section11.2 条件随机场的定义与形式](Chapter11/s11.2.md)
    * [Section11.3 条件随机场的概率计算问题](Chapter11/s11.3.md)
    * [Section11.4 条件随机场的计算方法](Chapter11/s11.4.md)
    * [Section11.5 条件随机场的预测算法](Chapter11/s11.5.md)
* [Chapter12 统计学习方法的总结](Chapter12/C12.md)

