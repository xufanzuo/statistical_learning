# Chapter1 统计学习方法概论
## 1.1 统计学习
* 统计学习(statistical learning)：是关于计算机基于数据结构构建概率统计模型并运用模型对数据进行预测与分析的一门学科。
* statistical learning 的学习对象是数据(data)。从数据出发，提取数据的特征，抽象出数据的模型，然后回到对数据的分析与预测。
* statistical learning由以下几个构成：
  * supervised learning 监督学习
  * unsupervised learning 非监督学习
  * semisupervised learning 半监督学习
  * reinforcement learning  强化学习
* supervised learning : 从 training data 集合出发，假设数据是独立同分布产生的；并且要学习的模型是某个函数的集合，称为假设空间(hypothesis space);应用某个评价准则(evaluation criterion),从假设空间选取一个最优的模型，应用于test data.

## 1.2 Supervised Learning
1. 输入空间、特征空间与输出空间
在监督学习中，将输入与输出所有可能的取值的集合分别称为 input space 和 output space。
每个具体的输入是一个 实例(instance)，通常由 特征向量(feature vector),所有的 feature vecture 存在的空间称为 feature space . 特征空间的每一维对应于一个特征。输入实例x的特征向量记作：
$$ x = (x^{(1)},x^{(2)},...,x^{(i)},...,x^{(n)})^T $$
训练集：
$$ T = \{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\} $$

2. 联合概率分布
    监督学习假设输入与输出的随机变量 X 和 Y 遵循联合概率分布 $P(X,Y)$。$P(X,Y)$表示分布函数，或分布密度函数。

3. 假设空间
   监督学习的目的在于学习一个由输入到输出的映射，这个映射的集合就是假设空间(hypothesis space).
   监督学习的模型可以是概率模型或非概率模型，由条件概率分布$P(X,Y)$或决策函数(decision function) $Y=f(x)$表示。

## 1.3 统计学习三要素
统计学习方法都是由模型、策略和算法构成。
方法 = 模型 + 策略 + 算法

### 1.3.1模型
在 supervised learning 中，模型就是所要学习的条件概率分布或决策函数。模型的hypothesis space包含所有可能的条件概率分布或决策函数。

### 1.3.2 策略
1. 损失函数和风险函数
 supervised learning的问题是在hypothesis space中选取模型f作为决策函数，对于给定的输入X,由$f(x)$给出相应的输出Y,这个输出的预测值f(x)和真实值Y可能不一致，用一个损失函数(loss function)或代价函数(cost function)来度量预测错误的程度。损失函数是f(x)和Y的非负实值函数，记住L(Y,f(x))
 常用损失函数：
(1) 0-1 loss function
$$ L(Y,f(X)) = \begin{cases}
    1 & Y\neq f(X) \\
    0 & Y=f(X)
\end{cases} $$
(2) quadratic loss function
$$ L(Y,f(X))=(Y-f(X))^2 $$
(3) absolute loss function
$$ L(Y,f(X))=|Y - f(X) |$$
(4)loglikelihood loss function 对数似然损失函数
$$ L(Y,P(Y|X)) = -logP(Y|X) $$
损失函数值越小，模型就越好，由于模型的输入、输出(X,Y)是随机变量，遵循联合分布P(X,Y),所以损失函数的期望是：
$$ R_{exp}(f)=E_P[L(Y,f(x))]=\int_{x*y} L(y,f(x))P(x,y)d_xd_y$$
这个是理论上模型f(x)关于联合分布P(X,Y)的平均意义下的损失，称为风险函数(risk function)
学习的目标就是选择期望风险最小的模型.由于联合分布P(X,Y)是未知的，$R_{exp}(f)$不能直接计算，实际上，如果知道